{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST classification with Convolutional neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data\n",
    "The MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST training data\n",
    "each sample on the MNIST dataset consist on a 784 feature vector encoding a 28x28 grayscale image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gqP8HZSqoe0qwCdEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5a044f358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "imgDigit = mnist.train.images[1]\n",
    "plt.imshow(imgDigit.reshape([28,28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight initialization routines\n",
    "One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients. Since we're using ReLU neurons, it is also good practice to initialize them with a slightly positive initial bias to avoid \"dead neurons\". Instead of doing this repeatedly while we build the model, let's create two handy functions to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create placeholders (I/O for our model/graph)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# Convert the feature vector to a (-1)x28x28x1 image\n",
    "# The -1 has the same effect as the \"None\" value, and will\n",
    "# be used to inform a variable batch size\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# First layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Third layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# Add dropout to the fully connected layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Last output layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a loss function and how to optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build graph\n",
    "Now we will initialize our variables, and create a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train graph (model/hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.88\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 0.9\n",
      "step 400, training accuracy 1\n",
      "step 500, training accuracy 0.88\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 1\n",
      "step 1000, training accuracy 0.98\n",
      "step 1100, training accuracy 0.96\n",
      "step 1200, training accuracy 0.96\n",
      "step 1300, training accuracy 1\n",
      "step 1400, training accuracy 1\n",
      "step 1500, training accuracy 0.98\n",
      "step 1600, training accuracy 0.96\n",
      "step 1700, training accuracy 0.94\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    # Get batch of 50 images\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    \n",
    "    # Print each 100 epochs\n",
    "    if i%100 == 0:\n",
    "        # Calculate train accuracy\n",
    "        train_accuracy = accuracy.eval(session=sess, feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    \n",
    "    # Train actually here\n",
    "    train_step.run(session=sess, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9743\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})) \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
