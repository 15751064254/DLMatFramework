{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba tutorial\n",
    "It's a JIT on llvm (Backend part) that compile CPU/GPU code infered from python code. It needs less changes compared to cython, but needs that you fix the data type of the functions that you want to accelerate. To use is quite simple you just need to add a decorator(PRAGMA) to the python code.\n",
    "In other words, Numba turns python into a compiled language with GPU/CPU target.\n",
    "\n",
    "### Numba modes\n",
    "* Object mode: Compiled code operates on python objects. Not fast only improve loop performance\n",
    "* nopython mode: Full compiled code that operates on \"machine native data\"\n",
    "\n",
    "### References\n",
    "* https://eng.climate.com/2015/04/09/numba-vs-cython-how-to-choose/\n",
    "* https://www.youtube.com/watch?v=QpaapVaL8Fw\n",
    "* https://www.youtube.com/watch?v=eYIPEDnp5C4\n",
    "* https://www.youtube.com/watch?v=06VErVj9MaQ&t=1509s\n",
    "* https://www.youtube.com/watch?v=SzBi3xdEF2Y&t=4872s\n",
    "* https://ipython.org/ipython-doc/3/interactive/magics.html\n",
    "* http://jakevdp.github.io/blog/2012/08/24/numba-vs-cython/\n",
    "* https://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/\n",
    "* http://numba.pydata.org/numba-doc/dev/user/examples.html\n",
    "* https://julien.danjou.info/blog/2015/guide-to-python-profiling-cprofile-concrete-case-carbonara\n",
    "* http://rlhick.people.wm.edu/posts/comparing-the-speed-of-matlab-versus-pythonnumpy.html\n",
    "* http://stackoverflow.com/questions/5217167/how-many-cuda-cores-does-each-multiprocessor-of-a-gpu-have\n",
    "* https://www.nvidia.com/en-us/geforce/products/10series/titan-x-pascal/\n",
    "* https://docs.python.org/3.0/library/timeit.html\n",
    "* http://numba.pydata.org/numba-doc/dev/user/examples.html\n",
    "* http://numba.pydata.org/numba-doc/dev/user/vectorize.html\n",
    "* http://numba.pydata.org/numba-doc/0.13/CUDAJit.html#\n",
    "* http://numba.pydata.org/numba-doc/dev/cuda/index.html\n",
    "* http://numba.pydata.org/numba-doc/dev/cuda/simulator.html\n",
    "* http://python-3-patterns-idioms-test.readthedocs.io/en/latest/index.html\n",
    "* https://blog.dominodatalab.com/interactive-dashboards-in-jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "# Add jit decorator to use LLVM to compile to native code.\n",
    "@jit\n",
    "def calculate_mean_numba(x_vec):\n",
    "    total = 0\n",
    "    # Iterate on x_vec\n",
    "    for xVal in x_vec:\n",
    "        total = total + xVal\n",
    "    \n",
    "    return total / len(x_vec)\n",
    "\n",
    "# Normal python\n",
    "def calculate_mean(x_vec):\n",
    "    total = 0\n",
    "    # Iterate on x_vec\n",
    "    for xVal in x_vec:\n",
    "        total = total + xVal\n",
    "    \n",
    "    return total / len(x_vec)\n",
    "\n",
    "# Using numpy\n",
    "def calculate_mean_numpy(x_vec):\n",
    "    return np.mean(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big vector shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Create random vector with 10000 elements\n",
    "big_vec = np.random.rand(10000)\n",
    "print('Big vector shape:',big_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using python version\n",
    "Actually the simple naive for-loop on python is 10x slower than matlab\n",
    "```matlab\n",
    "function calcMean = simpleMean(vecIn)\n",
    "\ttotal = 0;\n",
    "\tfor i=1:size(vecIn,1)\n",
    "\t\ttotal = total + vecIn(i);\n",
    "\tend\n",
    "\tcalcMean = total / size(vecIn,1);\n",
    "end\n",
    "\n",
    ">> a = rand(10000,1);                \n",
    ">> res1 = simpleMean(a)              \n",
    "\n",
    "res1 =\n",
    "\n",
    "    0.4996\n",
    "\n",
    ">> res2 = mean(a)\n",
    "\n",
    "res2 =\n",
    "\n",
    "    0.4996\n",
    "\n",
    ">> f = @() simpleMean(a);\n",
    ">> timeit(f)                         \n",
    "\n",
    "ans =\n",
    "\n",
    "   1.5744e-04\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.3 ms per loop\n",
      "Mean value(Pure python) is 0.499933\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_mean(big_vec)\n",
    "mean = calculate_mean(big_vec)\n",
    "print('Mean value(Pure python) is %f' % (mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.62 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 18.7 µs per loop\n",
      "Mean value(Numpy) is 0.499933\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_mean_numpy(big_vec)\n",
    "mean_numpy = calculate_mean_numpy(big_vec)\n",
    "print('Mean value(Numpy) is %f' % (mean_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Numba version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6116.44 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 9.22 µs per loop\n",
      "Mean value(Numba CPU) is 0.499933\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_mean_numba(big_vec)\n",
    "mean2 = calculate_mean_numba(big_vec)\n",
    "print('Mean value(Numba CPU) is %f' % (mean2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using GPU\n",
    "Numba also provide computations with CUDA, one of it's coolest features is that it accept numpy arrays. \n",
    " * ufunc: Universal functions, element-wise functions.\n",
    " \n",
    " By using numba.vectorize you transform your scalar function into a element-wise function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numba.cuda\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU b'TITAN X (Pascal)' compute capability(major): 6\n",
      "Number of streaming multiprocessors: 28\n",
      "Number cores per multiprocessor: 128\n",
      "Total cores on GPU: 3584\n",
      "Warp size: 32\n"
     ]
    }
   ],
   "source": [
    "myGpu = numba.cuda.get_current_device()\n",
    "nMultiProcessors = myGpu.MULTIPROCESSOR_COUNT\n",
    "# Check NVIDIA Architecture\n",
    "nCoresPerCapability = {\n",
    "    1:8,\n",
    "    2:32,\n",
    "    3:192,\n",
    "    5:128,\n",
    "    6:128\n",
    "}\n",
    "print (\"Running on GPU\", myGpu.name, \"compute capability(major):\", myGpu.compute_capability[0])\n",
    "print (\"Number of streaming multiprocessors:\",nMultiProcessors)\n",
    "print (\"Number cores per multiprocessor:\",nCoresPerCapability[myGpu.compute_capability[0]])\n",
    "print (\"Total cores on GPU:\",nMultiProcessors*nCoresPerCapability[myGpu.compute_capability[0]])\n",
    "print (\"Warp size:\", myGpu.WARP_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizes functions\n",
    "Those functions will run on each element of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@numba.vectorize(['float32(float32)'], target='cpu')\n",
    "def squareStuff_cpu(x):\n",
    "    return x*x\n",
    "\n",
    "@numba.vectorize(['float32(float32)'], target='parallel')\n",
    "def squareStuff_parallel(x):\n",
    "    return x*x\n",
    "\n",
    "@numba.vectorize(['float32(float32)'], target='cuda')\n",
    "def squareStuff_cuda(x):\n",
    "    return x*x\n",
    "\n",
    "@numba.vectorize(['float64(float64, float64)'], target='cpu')\n",
    "def sin_cos_cpu(x,y):\n",
    "    return math.sin(x)*math.cos(y)\n",
    "\n",
    "@numba.vectorize(['float64(float64, float64)'], target='parallel')\n",
    "def sin_cos_parallel(x,y):\n",
    "    return math.sin(x)*math.cos(y)\n",
    "\n",
    "@numba.vectorize(['float32(float64, float64)'], target='cuda')\n",
    "def sin_cos_cuda(x,y):\n",
    "    return math.sin(x)*math.cos(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/numba/cuda/compiler.py:233: UserWarning: Could not autotune, using default tpb of 128\n",
      "  warnings.warn('Could not autotune, using default tpb of 128')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time\n",
      "The slowest run took 11.16 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 858 ns per loop\n",
      "\n",
      "CPU cores time\n",
      "1000 loops, best of 3: 219 µs per loop\n",
      "\n",
      "GPU cores time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/numba/cuda/compiler.py:233: UserWarning: Could not autotune, using default tpb of 128\n",
      "  warnings.warn('Could not autotune, using default tpb of 128')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 797 µs per loop\n"
     ]
    }
   ],
   "source": [
    "# Create array from 0 to 19\n",
    "a = np.arange(20, dtype=np.float32)\n",
    "\n",
    "# Run on CPU\n",
    "resCPU = squareStuff_cpu(a)\n",
    "\n",
    "# Run on available cores\n",
    "resPar = squareStuff_parallel(a)\n",
    "\n",
    "# Run on available cores\n",
    "resGPU = squareStuff_cuda(a)\n",
    "\n",
    "# Run with timeit\n",
    "print('CPU time')\n",
    "%timeit squareStuff_cpu(a)\n",
    "print('\\nCPU cores time')\n",
    "%timeit squareStuff_parallel(a)\n",
    "print('\\nGPU cores time')\n",
    "%timeit squareStuff_cuda(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on CPU\n",
      " [ 0.          0.84147096  0.98935825  0.95637596  0.92002606 -0.61604047\n",
      "  0.69605851 -0.53659838  0.0795185   0.14993681  0.82687956 -0.86000788\n",
      "  0.12372269 -0.85561359 -0.98363125  0.80131495 -0.59464198 -0.43578497\n",
      "  0.93349361 -0.78533506]\n",
      "Result on Cores\n",
      " [ 0.          0.84147096  0.98935825  0.95637596  0.92002606 -0.61604047\n",
      "  0.69605851 -0.53659838  0.0795185   0.14993681  0.82687956 -0.86000788\n",
      "  0.12372269 -0.85561359 -0.98363125  0.80131495 -0.59464198 -0.43578497\n",
      "  0.93349361 -0.78533506]\n",
      "Result on Gpu\n",
      " [ 0.          0.84147102  0.98935825  0.95637596  0.92002606 -0.61604047\n",
      "  0.69605851 -0.53659838  0.07951849  0.14993681  0.82687956 -0.86000788\n",
      "  0.12372269 -0.85561359 -0.98363125  0.80131495 -0.59464198 -0.43578494\n",
      "  0.93349361 -0.78533512]\n"
     ]
    }
   ],
   "source": [
    "print('Result on CPU\\n',resCPU)\n",
    "print('Result on Cores\\n',resPar)\n",
    "print('Result on Gpu\\n',resGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/numba/cuda/compiler.py:233: UserWarning: Could not autotune, using default tpb of 128\n",
      "  warnings.warn('Could not autotune, using default tpb of 128')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU vectorize correct: True\n",
      "GPU vectorize correct: True\n",
      "CPU(par) vectorize correct: True\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "n = 80000000\n",
    "x = np.linspace(0,np.pi,n)\n",
    "y = np.linspace(0,np.pi,n)\n",
    "\n",
    "# Check result\n",
    "refAns = np.sin(x) * np.cos(y)\n",
    "resCpuVec = sin_cos_cpu(x,y)\n",
    "resCpuParVec = sin_cos_parallel(x,y)\n",
    "resGpuVec = sin_cos_cuda(x,y)\n",
    "\n",
    "#%timeit sin_cos_cuda(x,y)\n",
    "\n",
    "print(\"CPU vectorize correct:\", np.allclose(refAns,resCpuVec))\n",
    "print(\"GPU vectorize correct:\", np.allclose(refAns,resGpuVec))\n",
    "print(\"CPU(par) vectorize correct:\", np.allclose(refAns,resCpuParVec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time\n",
      "1 loop, best of 3: 4.35 s per loop\n",
      "\n",
      "CPU cores time\n",
      "1 loop, best of 3: 594 ms per loop\n",
      "\n",
      "GPU cores time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/numba/cuda/compiler.py:233: UserWarning: Could not autotune, using default tpb of 128\n",
      "  warnings.warn('Could not autotune, using default tpb of 128')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 938 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Run with timeit\n",
    "print('CPU time')\n",
    "%timeit sin_cos_cpu(x,y)\n",
    "print('\\nCPU cores time')\n",
    "%timeit sin_cos_parallel(x,y)\n",
    "print('\\nGPU cores time')\n",
    "%timeit sin_cos_cuda(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Cuda cores on python\n",
    "Numba support the creation of cuda kernels using python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "# Create a kernel that add 2 vectors\n",
    "@numba.cuda.jit('void(float32[:], float32[:], float32[:])')\n",
    "def addVecsKernel(vec_a, vec_b, vec_out):\n",
    "    \n",
    "    # Basic code (almost all kernels do the same) to get the kernel index coordinates\n",
    "    thread_x = cuda.threadIdx.x\n",
    "    block_x = cuda.blockIdx.x\n",
    "    threads_per_block = cuda.blockDim.x\n",
    "    \n",
    "    # Calculate thread index\n",
    "    idxThread = thread_x+ block_x * threads_per_block\n",
    "    \n",
    "    # Avoid calculating out of the array\n",
    "    if idxThread >= vec_out.size:\n",
    "        return\n",
    "    \n",
    "    # Do the calculation    \n",
    "    vec_out[idxThread] = vec_a[idxThread] + vec_b[idxThread]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Launch kernel\n",
    "\n",
    "* thread count: Set to the warp size of the GPU (or multiples of the warp size)\n",
    "* block count: ceil(SizeArray/Thread_count)\n",
    "\n",
    "This will launch more threads than elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads per block 32\n",
      "Blocks per grid 1\n",
      "VecA:\n",
      " [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.]\n",
      "VecB:\n",
      " [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.]\n",
      "VecOut:\n",
      " [  0.   2.   4.   6.   8.  10.  12.  14.  16.  18.  20.  22.  24.  26.  28.\n",
      "  30.  32.  34.  36.  38.]\n"
     ]
    }
   ],
   "source": [
    "# Create data\n",
    "n = 20\n",
    "VecA = np.arange(n, dtype=np.float32)\n",
    "VecB = np.arange(n, dtype=np.float32)\n",
    "VecOut = np.empty_like(VecA)\n",
    "\n",
    "# Launch the kernel\n",
    "thread_count = myGpu.WARP_SIZE\n",
    "block_count = int(math.ceil(float(n)/thread_count))\n",
    "\n",
    "print(\"Threads per block\", thread_count)\n",
    "print(\"Blocks per grid\", block_count)\n",
    "\n",
    "# griddim is the number of thread-block per grid.\n",
    "# blockdim is the number of threads per block\n",
    "# foo[griddim, blockdim](aryA, aryB)\n",
    "griddim = (block_count,1)\n",
    "blockdim = (thread_count,1)\n",
    "\n",
    "threadsperblock = myGpu.WARP_SIZE\n",
    "blockspergrid = math.ceil((n + (threadsperblock - 1)) / threadsperblock)\n",
    "\n",
    "addVecsKernel[blockspergrid,threadsperblock](VecA,VecB,VecOut)\n",
    "print('VecA:\\n',VecA)\n",
    "print('VecB:\\n',VecB)\n",
    "print('VecOut:\\n',VecOut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
