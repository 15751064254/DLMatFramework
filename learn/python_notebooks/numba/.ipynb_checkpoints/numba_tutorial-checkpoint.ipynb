{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba tutorial\n",
    "It's a JIT on llvm (Backend part) that compile CPU/GPU code infered from python code. It needs less changes compared to cython, but needs that you fix the data type of the functions that you want to accelerate. To use is quite simple you just need to add a decorator(PRAGMA) to the python code.\n",
    "In other words, Numba turns python into a compiled language with GPU/CPU target.\n",
    "\n",
    "### Numba modes\n",
    "* Object mode: Compiled code operates on python objects. Not fast only improve loop performance\n",
    "* nopython mode: Full compiled code that operates on \"machine native data\"\n",
    "\n",
    "### References\n",
    "* https://eng.climate.com/2015/04/09/numba-vs-cython-how-to-choose/\n",
    "* https://www.youtube.com/watch?v=eYIPEDnp5C4\n",
    "* https://www.youtube.com/watch?v=06VErVj9MaQ&t=1509s\n",
    "* https://ipython.org/ipython-doc/3/interactive/magics.html\n",
    "* http://jakevdp.github.io/blog/2012/08/24/numba-vs-cython/\n",
    "* https://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/\n",
    "* http://numba.pydata.org/numba-doc/dev/user/examples.html\n",
    "* https://julien.danjou.info/blog/2015/guide-to-python-profiling-cprofile-concrete-case-carbonara\n",
    "* http://rlhick.people.wm.edu/posts/comparing-the-speed-of-matlab-versus-pythonnumpy.html\n",
    "* http://stackoverflow.com/questions/5217167/how-many-cuda-cores-does-each-multiprocessor-of-a-gpu-have\n",
    "* https://www.nvidia.com/en-us/geforce/products/10series/titan-x-pascal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "# Add jit decorator to use LLVM to compile to native code.\n",
    "@jit\n",
    "def calculate_mean_numba(x_vec):\n",
    "    total = 0\n",
    "    # Iterate on x_vec\n",
    "    for xVal in x_vec:\n",
    "        total = total + xVal\n",
    "    \n",
    "    return total / len(x_vec)\n",
    "\n",
    "# Normal python\n",
    "def calculate_mean(x_vec):\n",
    "    total = 0\n",
    "    # Iterate on x_vec\n",
    "    for xVal in x_vec:\n",
    "        total = total + xVal\n",
    "    \n",
    "    return total / len(x_vec)\n",
    "\n",
    "# Using numpy\n",
    "def calculate_mean_numpy(x_vec):\n",
    "    return np.mean(x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big vector shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Create random vector with 10000 elements\n",
    "big_vec = np.random.rand(10000)\n",
    "print('Big vector shape:',big_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.3 ms per loop\n",
      "Mean value(Pure python) is 0.499933\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_mean(big_vec)\n",
    "mean = calculate_mean(big_vec)\n",
    "print('Mean value(Pure python) is %f' % (mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.62 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 18.7 µs per loop\n",
      "Mean value(Numpy) is 0.499933\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_mean_numpy(big_vec)\n",
    "mean_numpy = calculate_mean_numpy(big_vec)\n",
    "print('Mean value(Numpy) is %f' % (mean_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Numba version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6116.44 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 9.22 µs per loop\n",
      "Mean value(Numba CPU) is 0.499933\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_mean_numba(big_vec)\n",
    "mean2 = calculate_mean_numba(big_vec)\n",
    "print('Mean value(Numba CPU) is %f' % (mean2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using GPU\n",
    "Numba also provide computations with CUDA, one of it's coolest features is that it accept numpy arrays. \n",
    " * ufunc: Universal functions, element-wise functions.\n",
    " \n",
    " By using numba.vectorize you transform your scalar function into a element-wise function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numba.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU b'TITAN X (Pascal)' compute capability(major): 6\n",
      "Number of streaming multiprocessors: 28\n",
      "Number cores per multiprocessor: 128\n",
      "Total cores on GPU: 3584\n"
     ]
    }
   ],
   "source": [
    "myGpu = numba.cuda.get_current_device()\n",
    "nMultiProcessors = myGpu.MULTIPROCESSOR_COUNT\n",
    "# Check NVIDIA Architecture\n",
    "nCoresPerCapability = {\n",
    "    1:8,\n",
    "    2:32,\n",
    "    3:192,\n",
    "    5:128,\n",
    "    6:128\n",
    "}\n",
    "print (\"Running on GPU\", myGpu.name, \"compute capability(major):\", myGpu.compute_capability[0])\n",
    "print (\"Number of streaming multiprocessors:\",nMultiProcessors)\n",
    "print (\"Number cores per multiprocessor:\",nCoresPerCapability[myGpu.compute_capability[0]])\n",
    "print (\"Total cores on GPU:\",nMultiProcessors*nCoresPerCapability[myGpu.compute_capability[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-47760e0685f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mnumba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'float32(float32,float32)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float64(float64,float64)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msin_cos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gpu' is not defined"
     ]
    }
   ],
   "source": [
    "@numba.vectorize(['float32(float32,float32)', 'float64(float64,float64)'], target=gpu)\n",
    "def sin_cos(x,y):\n",
    "    return math.sin(x) * math.cos(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
